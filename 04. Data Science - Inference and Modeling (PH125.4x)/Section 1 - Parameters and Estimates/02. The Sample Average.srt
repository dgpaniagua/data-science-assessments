0
00:00:00,000 --> 00:00:05,917


1
00:00:05,917 --> 00:00:08,250
RAFAEL IRIZARRY: Taking an opinion poll is being modeled

2
00:00:08,250 --> 00:00:11,600
as taking a random sample from an urn.

3
00:00:11,600 --> 00:00:16,050
We are proposing the use of the proportion of blue beads in our sample

4
00:00:16,050 --> 00:00:19,010
as an estimate of the parameter p.

5
00:00:19,010 --> 00:00:21,180
Once we have this estimate, we can easily

6
00:00:21,180 --> 00:00:24,120
report an estimate of the spread, 2p minus 1.

7
00:00:24,120 --> 00:00:28,710
But for simplicity, we will illustrate the concept of statistical inference

8
00:00:28,710 --> 00:00:31,590
for estimating p.

9
00:00:31,590 --> 00:00:35,550
We will use our knowledge of probability to defend our use of the sample

10
00:00:35,550 --> 00:00:38,670
proportion, and quantify how close we think

11
00:00:38,670 --> 00:00:42,400
it is from the population proportion p.

12
00:00:42,400 --> 00:00:45,690
We start by defining the random variable X. X is

13
00:00:45,690 --> 00:00:50,700
going to be 1 if we pick a blue bead at random, and 0 if it's red.

14
00:00:50,700 --> 00:00:55,260
This implies that we're assuming that the population, the beads in the urn,

15
00:00:55,260 --> 00:00:57,960
are a list of 0s and 1s.

16
00:00:57,960 --> 00:01:02,640
If we sample N beads, then the average of the draws X_1 through X_N

17
00:01:02,640 --> 00:01:06,770
is equivalent to the proportion of blue beads in our sample.

18
00:01:06,770 --> 00:01:10,320
This is because adding the Xs is equivalent to counting the blue beads,

19
00:01:10,320 --> 00:01:14,350
and dividing by the total N turns this into a proportion.

20
00:01:14,350 --> 00:01:18,480
We use the symbol X-bar to represent this average.

21
00:01:18,480 --> 00:01:22,950
In general, in statistics textbooks, a bar on top of a symbol

22
00:01:22,950 --> 00:01:25,410
means the average.

23
00:01:25,410 --> 00:01:28,050
The theory we just learned about the sum of draws

24
00:01:28,050 --> 00:01:34,050
becomes useful, because we know the distribution of the sum N times X-bar.

25
00:01:34,050 --> 00:01:36,660
We know the distribution of the average X-bar,

26
00:01:36,660 --> 00:01:39,990
because N is a non random constant.

27
00:01:39,990 --> 00:01:43,440
For simplicity, let's assume that the draws are independent.

28
00:01:43,440 --> 00:01:46,700
After we see each sample bead, we return it to the urn.

29
00:01:46,700 --> 00:01:49,740
It's a sample with replacement.

30
00:01:49,740 --> 00:01:53,820
In this case, what do we know about the distribution of the sum of draws?

31
00:01:53,820 --> 00:01:57,210
First, we know that the expected value of the sum of draws

32
00:01:57,210 --> 00:02:01,530
is N times the average of the values in the urn.

33
00:02:01,530 --> 00:02:04,560
We know that the average of the 0s and 1s in the urn

34
00:02:04,560 --> 00:02:08,340
must be the proportion p, the value we want to estimate.

35
00:02:08,340 --> 00:02:10,560
Here, we encounter an important difference

36
00:02:10,560 --> 00:02:13,890
with what we did in the probability module.

37
00:02:13,890 --> 00:02:16,890
We don't know what is in the urn.

38
00:02:16,890 --> 00:02:20,730
We know there are blue and red beads, but we don't know how many of each.

39
00:02:20,730 --> 00:02:22,410
This is what we're trying to find out.

40
00:02:22,410 --> 00:02:24,960
We're trying to estimate p.

41
00:02:24,960 --> 00:02:28,650
Just like we use variables to define unknowns in systems of equations,

42
00:02:28,650 --> 00:02:30,900
in statistical inference, we define parameters

43
00:02:30,900 --> 00:02:34,050
to define unknown parts of our models.

44
00:02:34,050 --> 00:02:37,140
In the urn model we are using to mimic an opinion poll,

45
00:02:37,140 --> 00:02:39,870
we do not know the proportion of blue beads in the urn.

46
00:02:39,870 --> 00:02:43,320
We define the parameter p to represent this quantity.

47
00:02:43,320 --> 00:02:46,540
We are going to estimate this parameter.

48
00:02:46,540 --> 00:02:50,190
Note that the ideas presented here, on how we estimate parameters

49
00:02:50,190 --> 00:02:52,890
and provide insights into how good these estimates are,

50
00:02:52,890 --> 00:02:56,080
extrapolate to many data science tasks.

51
00:02:56,080 --> 00:02:58,890
For example, we may ask, what is the difference

52
00:02:58,890 --> 00:03:02,880
in health improvement between patients receiving treatment and a control

53
00:03:02,880 --> 00:03:03,990
group?

54
00:03:03,990 --> 00:03:08,290
We may ask, what are the health effects of smoking on a population?

55
00:03:08,290 --> 00:03:12,060
What are the differences in racial groups of fatal shootings by police?

56
00:03:12,060 --> 00:03:15,960
What is the rate of change in life expectancy in the US during the last 10

57
00:03:15,960 --> 00:03:16,800
years?

58
00:03:16,800 --> 00:03:20,880
All these questions can be framed as a task of estimating

59
00:03:20,880 --> 00:03:23,750
a parameter from a sample.

60
00:03:23,750 --> 00:03:26,912


